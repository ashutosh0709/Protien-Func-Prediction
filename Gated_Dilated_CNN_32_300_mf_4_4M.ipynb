{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36073,"status":"ok","timestamp":1649147264933,"user":{"displayName":"Ashutosh Raman","userId":"11279823942514050971"},"user_tz":-330},"id":"tLKiBOouMMv4","outputId":"099a201a-e32f-411d-a76b-ce49de027ae1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJRU8PeYdddG"},"outputs":[],"source":["import numpy as np\n","import datetime\n","\n","def accuracy(y_true, y_pred, normalize=True, sample_weight=None):\n","    acc_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        #print('\\nset_true: {0}'.format(set_true), ', set_pred: {0}'.format(set_pred))\n","        tmp_a = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_a = 1\n","        else:\n","            tmp_a = len(set_true.intersection(set_pred))/\\\n","                    float( len(set_true.union(set_pred)) )\n","        acc_list.append(tmp_a)\n","    return np.mean(acc_list)\n","\n","def precision(y_true, y_pred, normalize=True, sample_weight=None):\n","    pre_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_prec = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_prec = 1\n","            pre_list.append(tmp_prec)\n","        elif len(set_pred) > 0:\n","            tmp_prec = len(set_true.intersection(set_pred))/\\\n","                    float(len(set_pred))\n","            pre_list.append(tmp_prec)\n","        else:\n","            None\n","    return np.mean(pre_list)\n","\n","def recall(y_true, y_pred, normalize=True, sample_weight=None):\n","    rec_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_rec = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_rec = 1\n","        else:\n","            tmp_rec = len(set_true.intersection(set_pred))/\\\n","                    float(len(set_true))\n","        rec_list.append(tmp_rec)\n","    return np.mean(rec_list)\n","\n","def f_score(y_true, y_pred, normalize=True, sample_weight=None):\n","    acc_list = []\n","    for i in range(y_true.shape[0]):\n","        set_true = set( np.where(y_true[i])[0] )\n","        set_pred = set( np.where(y_pred[i])[0] )\n","        tmp_a = None\n","        if len(set_true) == 0 and len(set_pred) == 0:\n","            tmp_a = 1\n","        else:\n","            tmp_a = (2*len(set_true.intersection(set_pred)))/\\\n","                    float( len(set_true) + len(set_pred))\n","        acc_list.append(tmp_a)\n","    return np.mean(acc_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJ3-760liiG3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649147266874,"user_tz":-330,"elapsed":1947,"user":{"displayName":"Ashutosh Raman","userId":"11279823942514050971"}},"outputId":"098bc4dd-e43d-4c19-a720-1581ddf74b73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Dataset Size : 3132\n"]}],"source":["from csv import writer\n","import pandas as pd\n","\n","def test_segment(filename, low, up):\n","    myFile = open(filename, 'w', newline = '')\n","    with myFile:\n","        csv_writer = writer(myFile)\n","        for j, row in enumerate(seqData):\n","            segment = [ ]\n","            if(len(row) > low and len(row) < up):\n","                segment.append(row)\n","                for item in label[j]:\n","                    segment.append(item)\n","                csv_writer.writerow(segment)\n","    myFile.close()\n","\n","dataframe = pd.read_csv(\"/content/gdrive/MyDrive/B_tech_minor_project/dataset/MF/testData1.csv\", header=None) #Change the path\n","dataset = dataframe.values\n","seqData = dataset[:,0]\n","label = dataset[:,1:len(dataset[0])]\n","print('Original Dataset Size : %s' %len(dataset))\n","test_segment('testData200.csv', 0, 201)\n","test_segment('testData500.csv', 200, 501)\n","test_segment('testData1000.csv', 500, 1001)\n","test_segment('testData16000.csv', 1000, 16000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35nv9VuTSZoV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649147269273,"user_tz":-330,"elapsed":2410,"user":{"displayName":"Ashutosh Raman","userId":"11279823942514050971"}},"outputId":"c3f0d708-13d8-472c-fa30-5eced93ca058"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Dataset Size : 32280\n","(32280,) (32280, 135)\n","Non-overlapping Region: 150\n","Segment Size: 200\n","84011 9335\n","(84011, 135) (9335, 135)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import math\n","\n","def segment(dataset, label, seg_size, overlap):\n","    print(\"Non-overlapping Region: %s\" %overlap)\n","    print(\"Segment Size: %s\" %seg_size)\n","  \n","    seq_data, label_data = [], []\n","    for j, row in enumerate(dataset):\n","        if(len(row) < 2001):\n","            pos = math.ceil(len(row)/overlap)\n","            if(pos < math.ceil(seg_size/overlap)):\n","                pos = math.ceil(seg_size/overlap)\n","            for itr in range(pos - math.ceil(seg_size/overlap) + 1):\n","                init = itr * overlap\n","                if(len(row[init : init + seg_size]) > 50):\n","                    seq_data.append(row[init : init + seg_size])\n","                    label_data.append(label[j])\n","    return seq_data, label_data\n","\n","dataframe = pd.read_csv('/content/gdrive/MyDrive/B_tech_minor_project/dataset/MF/trainData.csv', header=None)\n","dataset = dataframe.values\n","print('Original Dataset Size : %s' %len(dataset))\n","X = dataset[:,0]\n","Y = dataset[:,1:len(dataset[0])]\n","del dataframe, dataset\n","print(X.shape, Y.shape)\n","\n","# Preparing For Training\n","segmentSize = 200\n","nonOL = segmentSize - 50\n","SEG = str(segmentSize)\n","\n","X, Y = segment(X, Y, segmentSize, nonOL)\n","nb_of_cls = len(Y[0])\n","\n","#Split the dataset\n","x_tr, x_val, y_tr, y_val = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n","del X, Y\n","\n","y_train = np.array(y_tr, dtype=float)\n","y_validate = np.array(y_val, dtype=float)\n","print(len(x_tr), len(x_val))\n","print(y_train.shape, y_validate.shape)\n","\n","del y_tr, y_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSSTBBiyzk9f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649147275464,"user_tz":-330,"elapsed":6195,"user":{"displayName":"Ashutosh Raman","userId":"11279823942514050971"}},"outputId":"f1d3d325-3d99-4631-f532-8094d20e5fc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating Dictionary:\n"]}],"source":["import math\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import backend as K\n","from keras.preprocessing import sequence\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","np.random.seed(7)\n","\n","def dictionary(chunk_size):\n","    dataframe = pd.read_csv('/content/gdrive/MyDrive/B_tech_minor_project/dataset/MF/trainData.csv', header=None)\n","    dataset = dataframe.values\n","    del dataframe\n","\n","    seq_dataset = dataset[:,0]\n","    print('Creating Dictionary:')\n","    dict = {}\n","    j = 0\n","    for row in seq_dataset:\n","        for i in range(len(row) - chunk_size + 1):\n","            key = row[i:i + chunk_size]\n","            if key not in dict:\n","                dict[key] = j\n","                j = j + 1\n","    del dataset, seq_dataset\n","    return(dict)\n","\n","def nGram(dataset, chunk_size, dictI):\n","    dict1 = list()\n","    for j, row in enumerate(dataset):\n","        string = row\n","        dict2 = list()\n","        for i in range(len(string) - chunk_size + 1):\n","            try:\n","                dict2.append(dictI[string[i:i + chunk_size]])\n","            except:\n","                None\n","        dict1.append(dict2)   \n","    return(dict1)\n","\n","# CREATING DICTIONARY\n","chunkSize = 4\n","dict_Prop = dictionary(chunkSize)\n","max_seq_len = segmentSize - chunkSize + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TOADdbxhjJ1v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649147924605,"user_tz":-330,"elapsed":649144,"user":{"displayName":"Ashutosh Raman","userId":"11279823942514050971"}},"outputId":"fa5772a9-7b1e-4b9d-a71a-cfbffc7f2119"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 197)]        0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 197, 32)      5123872     ['input_1[0][0]']                \n","                                                                                                  \n"," dropout (Dropout)              (None, 197, 32)      0           ['embedding[0][0]']              \n","                                                                                                  \n"," bi_cnn (Bi_CNN)                (None, 197, 128)     33024       ['dropout[0][0]']                \n","                                                                                                  \n"," bi_cnn_1 (Bi_CNN)              (None, 197, 128)     33024       ['dropout[0][0]']                \n","                                                                                                  \n"," bi_cnn_2 (Bi_CNN)              (None, 197, 128)     33024       ['dropout[0][0]']                \n","                                                                                                  \n"," bi_cnn_3 (Bi_CNN)              (None, 197, 128)     33024       ['dropout[0][0]']                \n","                                                                                                  \n"," bi_cnn_4 (Bi_CNN)              (None, 197, 128)     33024       ['dropout[0][0]']                \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 197, 128)    512         ['bi_cnn[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 197, 128)    512         ['bi_cnn_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 197, 128)    512         ['bi_cnn_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 197, 128)    512         ['bi_cnn_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 197, 128)    512         ['bi_cnn_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," leaky_re_lu (LeakyReLU)        (None, 197, 128)     0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," leaky_re_lu_1 (LeakyReLU)      (None, 197, 128)     0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," leaky_re_lu_2 (LeakyReLU)      (None, 197, 128)     0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," leaky_re_lu_3 (LeakyReLU)      (None, 197, 128)     0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," leaky_re_lu_4 (LeakyReLU)      (None, 197, 128)     0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," concatenate_5 (Concatenate)    (None, 197, 640)     0           ['leaky_re_lu[0][0]',            \n","                                                                  'leaky_re_lu_1[0][0]',          \n","                                                                  'leaky_re_lu_2[0][0]',          \n","                                                                  'leaky_re_lu_3[0][0]',          \n","                                                                  'leaky_re_lu_4[0][0]']          \n","                                                                                                  \n"," leaky_re_lu_5 (LeakyReLU)      (None, 197, 640)     0           ['concatenate_5[0][0]']          \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 640)         0           ['leaky_re_lu_5[0][0]']          \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 640)          0           ['global_average_pooling1d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," CLASSIFIER (Dense)             (None, 135)          86535       ['dropout_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 5,378,087\n","Trainable params: 5,376,807\n","Non-trainable params: 1,280\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/500\n","561/561 [==============================] - 45s 56ms/step - loss: 0.0730 - binary_accuracy: 0.9848 - val_loss: 0.1936 - val_binary_accuracy: 0.9891\n","Epoch 2/500\n","561/561 [==============================] - 30s 54ms/step - loss: 0.0489 - binary_accuracy: 0.9894 - val_loss: 0.0580 - val_binary_accuracy: 0.9894\n","Epoch 3/500\n","561/561 [==============================] - 31s 54ms/step - loss: 0.0381 - binary_accuracy: 0.9907 - val_loss: 0.0373 - val_binary_accuracy: 0.9909\n","Epoch 4/500\n","561/561 [==============================] - 31s 55ms/step - loss: 0.0302 - binary_accuracy: 0.9919 - val_loss: 0.0357 - val_binary_accuracy: 0.9920\n","Epoch 5/500\n","561/561 [==============================] - 31s 55ms/step - loss: 0.0242 - binary_accuracy: 0.9931 - val_loss: 0.0342 - val_binary_accuracy: 0.9927\n","Epoch 6/500\n","561/561 [==============================] - 31s 55ms/step - loss: 0.0194 - binary_accuracy: 0.9942 - val_loss: 0.0314 - val_binary_accuracy: 0.9932\n","Epoch 7/500\n","561/561 [==============================] - 31s 55ms/step - loss: 0.0157 - binary_accuracy: 0.9951 - val_loss: 0.0298 - val_binary_accuracy: 0.9936\n","Epoch 8/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0129 - binary_accuracy: 0.9958 - val_loss: 0.0278 - val_binary_accuracy: 0.9939\n","Epoch 9/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0109 - binary_accuracy: 0.9964 - val_loss: 0.0259 - val_binary_accuracy: 0.9941\n","Epoch 10/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0093 - binary_accuracy: 0.9969 - val_loss: 0.0249 - val_binary_accuracy: 0.9942\n","Epoch 11/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0081 - binary_accuracy: 0.9973 - val_loss: 0.0236 - val_binary_accuracy: 0.9944\n","Epoch 12/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0072 - binary_accuracy: 0.9976 - val_loss: 0.0237 - val_binary_accuracy: 0.9944\n","Epoch 13/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0065 - binary_accuracy: 0.9978 - val_loss: 0.0232 - val_binary_accuracy: 0.9945\n","Epoch 14/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0060 - binary_accuracy: 0.9980 - val_loss: 0.0229 - val_binary_accuracy: 0.9946\n","Epoch 15/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0055 - binary_accuracy: 0.9982 - val_loss: 0.0227 - val_binary_accuracy: 0.9947\n","Epoch 16/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0051 - binary_accuracy: 0.9983 - val_loss: 0.0228 - val_binary_accuracy: 0.9947\n","Epoch 17/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0048 - binary_accuracy: 0.9984 - val_loss: 0.0233 - val_binary_accuracy: 0.9947\n","Epoch 18/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0045 - binary_accuracy: 0.9985 - val_loss: 0.0232 - val_binary_accuracy: 0.9948\n","Epoch 19/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0042 - binary_accuracy: 0.9986 - val_loss: 0.0234 - val_binary_accuracy: 0.9948\n","Epoch 20/500\n","561/561 [==============================] - 31s 56ms/step - loss: 0.0041 - binary_accuracy: 0.9987 - val_loss: 0.0234 - val_binary_accuracy: 0.9948\n","Epoch 20: early stopping\n"]}],"source":["import math\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import backend as K\n","from keras.preprocessing import sequence\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","np.random.seed(7)\n","\n","'''\n","class Attention_layer(tf.keras.layers.Layer):\n","    def __init__(self,inputs):\n","        super(Attention_layer,self).__init__()\n","        self.W=self.add_weight(name='attention_weight', shape=(inputs,1),initializer='random_normal', trainable=True)\n","        self.b=self.add_weight(name='attention_bias', shape=(inputs,1),initializer='zeros', trainable=True) \n"," \n","    def call(self,x):\n","        # Alignment scores. Pass them through tanh function\n","        e = K.tanh(K.dot(x,self.W)+self.b)\n","        # Remove dimension of size 1\n","        e = K.squeeze(e, axis=-1)   \n","        # Compute the weights\n","        alpha = K.softmax(e)\n","        # Reshape to tensorFlow format\n","        alpha = K.expand_dims(alpha, axis=-1)\n","        # Compute the context vector\n","        context = x * alpha\n","        context = K.sum(context, axis=1)\n","        return context\n","\n","    def get_conig(self):\n","      config = super().get_cofig().copy()\n","      config.update({'inputs':inputs,})\n","      return config\n","\n","'''\n","\n","class Bi_CNN(tf.keras.layers.Layer):\n","    def __init__(self, no_of_filters, filter_size,dilation_rate):\n","        super(Bi_CNN,self).__init__()\n","        self.forward_cnn = tf.keras.layers.Conv1D(filters = no_of_filters, kernel_size=filter_size, dilation_rate=dilation_rate,\n","                                                  strides=1, padding='causal',activation='linear',use_bias=True)\n","        # self.backward_cnn = tf.keras.layers.Conv1D(filters = no_of_filters, kernel_size=filter_size, dilation_rate=dilation_rate,\n","        #                                            strides=1, padding='causal',activation='linear',use_bias=True)\n","        \n","        self.forward_gated_cnn = tf.keras.layers.Conv1D(filters = no_of_filters, kernel_size=filter_size, dilation_rate=dilation_rate,\n","                                                    strides=1, padding='causal',activation='sigmoid',use_bias=True)\n","        # self.backward_gated_cnn = tf.keras.layers.Conv1D(filters = no_of_filters, kernel_size=filter_size, dilation_rate=dilation_rate,\n","        #                                             strides=1, padding='causal',activation='sigmoid',use_bias=True)\n","        \n","        self.concat = tf.keras.layers.Concatenate(axis=-1)\n","        self.add = tf.keras.layers.Add()\n","\n","    def call(self, inputs, mode='Concat'):\n","        f_cnn = self.forward_cnn(inputs)                  # Forward Pass\n","        f_gated_cnn = self.forward_gated_cnn(inputs)\n","        f_int = tf.multiply(f_cnn, f_gated_cnn)\n","\n","        # r_input = tf.reverse(inputs, [-2])                # Backward Pass\n","        # b_cnn = self.backward_cnn(r_input)  \n","        # b_cnn = tf.reverse(b_cnn, [-2])\n","\n","        # b_gated_cnn = self.backward_gated_cnn(r_input)\n","        # b_gated_cnn = tf.reverse(b_gated_cnn, [-2])\n","\n","\n","        # b_int = tf.multiply(b_cnn, b_gated_cnn)\n","\n","\n","        # if mode is 'Concat':\n","        #     output = self.concat([f_int, b_int])\n","\n","        # elif mode == 'Add':\n","        #     output = self.add([f_int, b_int])\n","\n","        # else:\n","        #     output = f_int, b_int\n","        output = f_int\n","        return output\n","\n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({'no_of_filters': self.no_of_filters, 'filter_size': self.filter_size, 'dilation_rate': self.dilation_rate,})\n","        return config\n","\n","\n","def DC_CNN_Block(nb_filter, filter_length, dilation, l2_layer_reg):\n","    def f(input_):\n","        residual = input_\n","        layer_out = Bi_CNN(no_of_filters = nb_filter, filter_size = filter_length, dilation_rate=dilation)(input_)\n","        '''\n","        layer_out = layers.Conv1D(filters=nb_filter, kernel_size=filter_length, dilation_rate=dilation, \n","                                  activation='linear', padding='same', use_bias=True) (input_)\n","                                  '''\n","        layer_out = layers.BatchNormalization(epsilon=1.1e-5)(layer_out)\n","        layer_out = layers.LeakyReLU(alpha = 0.2)(layer_out)\n","        #network_out = layers.Add()([residual, layer_out])\n","        return layer_out\n","    return f\n","\n","embed_dim = 32\n","ff_dim = 300\n","\n","def DC_CNN_Model(top_words, seq_len, o_dim):\n","    #embed_dim = 32\n","    f_num = 128\n","    f_size = [4,4,4,4,4]\n","    #ff_dim = 200\n","\n","    _input = layers.Input(shape=(seq_len,))\n","    emd = layers.Embedding(top_words, embed_dim, input_length = seq_len)(_input)\n","    drop1 = layers.Dropout(0.3)(emd)\n","\n","    l1 = DC_CNN_Block(f_num, f_size[0], 1, 0.001)(drop1) \n","    l2 = DC_CNN_Block(f_num, f_size[1], 3, 0.001)(drop1)\n","    l3 = DC_CNN_Block(f_num, f_size[2], 5, 0.001)(drop1)\n","    l4 = DC_CNN_Block(f_num, f_size[3], 7, 0.001)(drop1)\n","    l5 = DC_CNN_Block(f_num, f_size[4], 9, 0.001)(drop1)\n","\n","    c_x = layers.Concatenate()([l1, l2, l3, l4, l5])\n","\n","    #x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation='linear', padding='valid')(c_x)\n","    #x = layers.BatchNormalization(epsilon=1.1e-5)(x)\n","    #x = layers.LeakyReLU(alpha = 0.2)(c_x)\n","    #x = layers.Lambda(lambda xin: K.sum(xin, axis=1))(x)\n","    x = layers.GlobalAveragePooling1D()(c_x)\n","    x = layers.Dropout(0.4)(x)\n","    _output = layers.Dense(o_dim, kernel_initializer='normal', activation='sigmoid', name='CLASSIFIER')(x)\n","\n","    model = keras.Model(inputs=_input, outputs=_output)\n","    model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n","                  # loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n","                  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005),\n","                  metrics = tf.keras.metrics.BinaryAccuracy(threshold=0.5))\n","    return model\n","\n","#CREATING N-GRAM\n","x_train = nGram(x_tr, chunkSize, dict_Prop)\n","x_validate = nGram(x_val, chunkSize, dict_Prop)\n","\n","# truncate and pad input sequences\n","x_train = sequence.pad_sequences(x_train, maxlen=max_seq_len)\n","x_validate = sequence.pad_sequences(x_validate, maxlen=max_seq_len)\n","\n","# Create & Compile the model\n","model = DC_CNN_Model(len(dict_Prop), max_seq_len, nb_of_cls)\n","print(model.summary())\n","early_stopping_monitor1 = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1)\n","history = model.fit(x_train, y_train,\n","          validation_data = (x_validate, y_validate),\n","          epochs = 500,\n","          batch_size = 150,\n","          callbacks=[early_stopping_monitor1],\n","          verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-f87om6sPbj"},"outputs":[],"source":["#pip install 'h5py==2.10.0' --force-reinstall"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIoEB24N2u8F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649149423190,"user_tz":-330,"elapsed":1498589,"user":{"displayName":"Ashutosh Raman","userId":"11279823942514050971"}},"outputId":"09836738-1cea-4dee-e6fd-23e2f0fb50c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting features based on GRU model...... \n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 135)               18360     \n","                                                                 \n"," dense_1 (Dense)             (None, 135)               18360     \n","                                                                 \n","=================================================================\n","Total params: 36,720\n","Trainable params: 36,720\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/1000\n","194/194 [==============================] - 1s 4ms/step - loss: 0.3496 - binary_accuracy: 0.9674 - val_loss: 0.0929 - val_binary_accuracy: 0.9894\n","Epoch 2/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0763 - binary_accuracy: 0.9895 - val_loss: 0.0719 - val_binary_accuracy: 0.9894\n","Epoch 3/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0682 - binary_accuracy: 0.9895 - val_loss: 0.0677 - val_binary_accuracy: 0.9894\n","Epoch 4/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0647 - binary_accuracy: 0.9895 - val_loss: 0.0643 - val_binary_accuracy: 0.9894\n","Epoch 5/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0615 - binary_accuracy: 0.9895 - val_loss: 0.0608 - val_binary_accuracy: 0.9894\n","Epoch 6/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0580 - binary_accuracy: 0.9895 - val_loss: 0.0567 - val_binary_accuracy: 0.9894\n","Epoch 7/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0535 - binary_accuracy: 0.9895 - val_loss: 0.0515 - val_binary_accuracy: 0.9894\n","Epoch 8/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0480 - binary_accuracy: 0.9895 - val_loss: 0.0454 - val_binary_accuracy: 0.9895\n","Epoch 9/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0416 - binary_accuracy: 0.9898 - val_loss: 0.0389 - val_binary_accuracy: 0.9900\n","Epoch 10/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0352 - binary_accuracy: 0.9904 - val_loss: 0.0326 - val_binary_accuracy: 0.9910\n","Epoch 11/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0292 - binary_accuracy: 0.9919 - val_loss: 0.0270 - val_binary_accuracy: 0.9925\n","Epoch 12/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0240 - binary_accuracy: 0.9934 - val_loss: 0.0222 - val_binary_accuracy: 0.9940\n","Epoch 13/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0195 - binary_accuracy: 0.9944 - val_loss: 0.0181 - val_binary_accuracy: 0.9947\n","Epoch 14/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0158 - binary_accuracy: 0.9953 - val_loss: 0.0148 - val_binary_accuracy: 0.9956\n","Epoch 15/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0128 - binary_accuracy: 0.9962 - val_loss: 0.0121 - val_binary_accuracy: 0.9965\n","Epoch 16/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0105 - binary_accuracy: 0.9970 - val_loss: 0.0101 - val_binary_accuracy: 0.9972\n","Epoch 17/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0087 - binary_accuracy: 0.9977 - val_loss: 0.0085 - val_binary_accuracy: 0.9977\n","Epoch 18/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0073 - binary_accuracy: 0.9982 - val_loss: 0.0073 - val_binary_accuracy: 0.9981\n","Epoch 19/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0063 - binary_accuracy: 0.9985 - val_loss: 0.0064 - val_binary_accuracy: 0.9984\n","Epoch 20/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0055 - binary_accuracy: 0.9988 - val_loss: 0.0057 - val_binary_accuracy: 0.9986\n","Epoch 21/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0049 - binary_accuracy: 0.9989 - val_loss: 0.0051 - val_binary_accuracy: 0.9988\n","Epoch 22/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0044 - binary_accuracy: 0.9991 - val_loss: 0.0047 - val_binary_accuracy: 0.9989\n","Epoch 23/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0040 - binary_accuracy: 0.9991 - val_loss: 0.0044 - val_binary_accuracy: 0.9990\n","Epoch 24/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0037 - binary_accuracy: 0.9992 - val_loss: 0.0041 - val_binary_accuracy: 0.9990\n","Epoch 25/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0035 - binary_accuracy: 0.9992 - val_loss: 0.0039 - val_binary_accuracy: 0.9991\n","Epoch 26/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0033 - binary_accuracy: 0.9993 - val_loss: 0.0037 - val_binary_accuracy: 0.9991\n","Epoch 27/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0031 - binary_accuracy: 0.9993 - val_loss: 0.0036 - val_binary_accuracy: 0.9992\n","Epoch 28/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0030 - binary_accuracy: 0.9993 - val_loss: 0.0035 - val_binary_accuracy: 0.9992\n","Epoch 29/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0028 - binary_accuracy: 0.9994 - val_loss: 0.0034 - val_binary_accuracy: 0.9992\n","Epoch 30/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0027 - binary_accuracy: 0.9994 - val_loss: 0.0033 - val_binary_accuracy: 0.9992\n","Epoch 31/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0026 - binary_accuracy: 0.9994 - val_loss: 0.0032 - val_binary_accuracy: 0.9993\n","Epoch 32/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0025 - binary_accuracy: 0.9994 - val_loss: 0.0032 - val_binary_accuracy: 0.9993\n","Epoch 33/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0025 - binary_accuracy: 0.9994 - val_loss: 0.0031 - val_binary_accuracy: 0.9993\n","Epoch 34/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0024 - binary_accuracy: 0.9994 - val_loss: 0.0031 - val_binary_accuracy: 0.9993\n","Epoch 35/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0024 - binary_accuracy: 0.9994 - val_loss: 0.0030 - val_binary_accuracy: 0.9993\n","Epoch 36/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0023 - binary_accuracy: 0.9995 - val_loss: 0.0030 - val_binary_accuracy: 0.9993\n","Epoch 37/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0022 - binary_accuracy: 0.9995 - val_loss: 0.0030 - val_binary_accuracy: 0.9993\n","Epoch 38/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0022 - binary_accuracy: 0.9995 - val_loss: 0.0030 - val_binary_accuracy: 0.9993\n","Epoch 39/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0022 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9993\n","Epoch 40/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0021 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9993\n","Epoch 41/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0021 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9993\n","Epoch 42/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0020 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 43/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0020 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 44/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0020 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9993\n","Epoch 45/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 46/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 47/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 48/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 49/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0018 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 50/1000\n","194/194 [==============================] - 1s 4ms/step - loss: 0.0018 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 51/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0018 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 52/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0018 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9993\n","Epoch 53/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0018 - binary_accuracy: 0.9995 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 54/1000\n","194/194 [==============================] - 1s 4ms/step - loss: 0.0017 - binary_accuracy: 0.9996 - val_loss: 0.0029 - val_binary_accuracy: 0.9994\n","Epoch 55/1000\n","194/194 [==============================] - 1s 3ms/step - loss: 0.0017 - binary_accuracy: 0.9996 - val_loss: 0.0029 - val_binary_accuracy: 0.9993\n","Epoch 56/1000\n","194/194 [==============================] - 1s 4ms/step - loss: 0.0017 - binary_accuracy: 0.9996 - val_loss: 0.0029 - val_binary_accuracy: 0.9993\n","Epoch 56: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f24e37bb8d0>"]},"metadata":{},"execution_count":8}],"source":["from keras.models import load_model\n","\n","def cls_predict(pred, normalize=True, sample_weight=None):\n","    s_mean = np.mean(pred, axis=0)\n","    m = max(s_mean)\n","    s_mean = (s_mean/m)\n","    return(list(s_mean))\n","\n","def final_model(filename):\n","    print('Extracting features based on GRU model...... ')\n","    dataframe2 = pd.read_csv(filename, header=None)\n","    dataset2 = dataframe2.values\n","    overlap = 50\n","    X_test = dataset2[:,0]\n","    Y_test = dataset2[:,1:len(dataset2[0])]\n","    c_p = []\n","    for tag, row in enumerate(X_test):\n","        pos = math.ceil(len(row) / overlap)\n","        if(pos < math.ceil(segmentSize/ overlap)):\n","            pos = math.ceil(segmentSize/ overlap)\n","        segment = [ ]\n","        for itr in range(pos - math.ceil(segmentSize/overlap) + 1):\n","            init = itr * overlap\n","            segment.append(row[init : init + segmentSize])\n","        seg_nGram = nGram(segment, chunkSize, dict_Prop)\n","        test_seg = sequence.pad_sequences(seg_nGram, maxlen=max_seq_len)\n","        preds = model.predict(test_seg)\n","        c_p.append(cls_predict(preds))\n","    c_p = np.array(c_p)\n","    return c_p, Y_test\n","\n","def create_nn_model(dim):\n","    n_model = keras.Sequential(\n","        [layers.Dense(dim, input_dim = dim, kernel_initializer='normal', activation='relu'),\n","        layers.Dense(dim, kernel_initializer='normal', activation='sigmoid'),]\n","        )\n","    n_model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n","                    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005),\n","                    metrics = tf.keras.metrics.BinaryAccuracy(threshold=0.5))\n","    return n_model\n","\n","# Creates a HDF5 file 'my_model.h5'\n","\n","#model_path = '/content/gdrive/MyDrive/B_tech_minor_project/dataset/BP/'+str(embed_dim)+'_model_'+str(ff_dim)+'_'+str(nonOL)+'_'+str(6)+'_'+ SEG +'.h5'\n","#model.save(model_path)\n","#del model  \n","#model = load_model(model_path)\n","\n","# Training\n","X_train_new, Y_train_new = final_model('/content/gdrive/MyDrive/B_tech_minor_project/dataset/MF/trainData.csv')\n","\n","# Training model 2\n","model1 = create_nn_model(Y_train_new[0].shape[0])\n","print(model1.summary())\n","early_stopping_monitor = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1)\n","model1.fit(X_train_new, Y_train_new.astype(None),\n","           callbacks = [early_stopping_monitor],\n","           validation_split = 0.1,\n","           epochs = 1000,\n","           batch_size = 150,\n","           verbose = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCBnJoGXQegI","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1649149579672,"user_tz":-330,"elapsed":156488,"user":{"displayName":"Ashutosh Raman","userId":"11279823942514050971"}},"outputId":"219044d3-d00a-439b-983e-0ec77627c849"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting features based on GRU model...... \n","(3132, 135) (3132, 135)\n","THRESHOLD IS =====>  0.01\n","Recall: 65.51962334529384      Precision: 53.95797742068511      F1-score1: 59.17939989440817       F1-score2: 55.07196637755276\n","THRESHOLD IS =====>  0.02\n","Recall: 63.60813365363174      Precision: 55.982893409287605      F1-score1: 59.55241716289444       F1-score2: 56.327988429569906\n","THRESHOLD IS =====>  0.03\n","Recall: 62.710145147884624      Precision: 56.70700523551994      F1-score1: 59.55768527056565       F1-score2: 56.70895373219081\n","THRESHOLD IS =====>  0.04\n","Recall: 61.98820673437532      Precision: 57.17337508004062      F1-score1: 59.48351708998184       F1-score2: 56.85462640576684\n","THRESHOLD IS =====>  0.05\n","Recall: 61.616468000567615      Precision: 57.52410198890083      F1-score1: 59.500000541776984       F1-score2: 57.03017004592621\n","THRESHOLD IS =====>  0.06\n","Recall: 61.24227322982112      Precision: 57.74059043621483      F1-score1: 59.43990431884815       F1-score2: 57.07331101502275\n","THRESHOLD IS =====>  0.07\n","Recall: 60.932566971838995      Precision: 57.91870005859147      F1-score1: 59.38742023403732       F1-score2: 57.123292837514164\n","THRESHOLD IS =====>  0.08\n","Recall: 60.55474662275429      Precision: 58.041022930764065      F1-score1: 59.27124467474094       F1-score2: 57.056755552980476\n","THRESHOLD IS =====>  0.09\n","Recall: 60.41791027902139      Precision: 58.23217445739823      F1-score1: 59.30490988751019       F1-score2: 57.13784653980733\n","THRESHOLD IS =====>  0.1\n","Recall: 60.15792122592889      Precision: 58.39200892943695      F1-score1: 59.2618126184836       F1-score2: 57.15074091093925\n","THRESHOLD IS =====>  0.11\n","Recall: 59.98391100881521      Precision: 58.45478210678211      F1-score1: 59.20947547961668       F1-score2: 57.122425250439676\n","THRESHOLD IS =====>  0.12\n","Recall: 59.78169730085439      Precision: 58.43219163059163      F1-score1: 59.09924162483632       F1-score2: 57.046335950212445\n","THRESHOLD IS =====>  0.13\n","Recall: 59.699747534996575      Precision: 58.48573968253968      F1-score1: 59.08650843091117       F1-score2: 57.04988586276619\n","THRESHOLD IS =====>  0.14\n","Recall: 59.68112258821071      Precision: 58.585168253968256      F1-score1: 59.12806740649128       F1-score2: 57.08934034187584\n","THRESHOLD IS =====>  0.15\n","Recall: 59.63855128127159      Precision: 58.67933968253968      F1-score1: 59.155057283410684       F1-score2: 57.141236792239724\n","THRESHOLD IS =====>  0.16\n","Recall: 59.54884745593557      Precision: 58.76267707253622      F1-score1: 59.15315024535525       F1-score2: 57.14873054015492\n","THRESHOLD IS =====>  0.17\n","Recall: 59.44528456501635      Precision: 58.83775775226303      F1-score1: 59.139960965306045       F1-score2: 57.14988487751616\n","THRESHOLD IS =====>  0.18\n","Recall: 59.28298145731096      Precision: 58.916085605447996      F1-score1: 59.0989640997864       F1-score2: 57.106917344127176\n","THRESHOLD IS =====>  0.19\n","Recall: 59.15526753649358      Precision: 58.97556725681725      F1-score1: 59.06528071688603       F1-score2: 57.09194136650751\n","THRESHOLD IS =====>  0.2\n","Recall: 59.08502488004403      Precision: 59.062873733441215      F1-score1: 59.073947230221144       F1-score2: 57.11053406230327\n","THRESHOLD IS =====>  0.21\n","Recall: 58.95731095922666      Precision: 59.09546965093615      F1-score1: 59.02630946063201       F1-score2: 57.089953323331734\n","THRESHOLD IS =====>  0.22\n","Recall: 58.877489758715804      Precision: 59.136061332885205      F1-score1: 59.00649227638631       F1-score2: 57.068515629480245\n","THRESHOLD IS =====>  0.23\n","Recall: 58.78702573147018      Precision: 59.21573195634793      F1-score1: 59.00060009504398       F1-score2: 57.08326354652701\n","THRESHOLD IS =====>  0.24\n","Recall: 58.680597464122364      Precision: 59.2143341076268      F1-score1: 58.94625761347556       F1-score2: 57.03749939156745\n","THRESHOLD IS =====>  0.25\n","Recall: 58.54490142325391      Precision: 59.18568015567374      F1-score1: 58.863546988582115       F1-score2: 56.96832101779138\n","THRESHOLD IS =====>  0.26\n","Recall: 58.43847315590611      Precision: 59.22900493102675      F1-score1: 58.831083507299454       F1-score2: 56.94855576814108\n","THRESHOLD IS =====>  0.27\n","Recall: 58.39590184896699      Precision: 59.28325562434712      F1-score1: 58.83623321337329       F1-score2: 56.94500815922948\n","THRESHOLD IS =====>  0.28\n","Recall: 58.300116408353965      Precision: 59.27473311421947      F1-score1: 58.78338530162674       F1-score2: 56.91510688411747\n","THRESHOLD IS =====>  0.29\n","Recall: 58.180384607587676      Precision: 59.31785281014568      F1-score1: 58.74361295005589       F1-score2: 56.87833845175517\n","THRESHOLD IS =====>  0.3\n","Recall: 58.042027860035525      Precision: 59.327054515036515      F1-score1: 58.67750656874781       F1-score2: 56.811643404217214\n","THRESHOLD IS =====>  0.31\n","Recall: 57.98526611745002      Precision: 59.397703543731204      F1-score1: 58.682987092422465       F1-score2: 56.79944313818554\n","THRESHOLD IS =====>  0.32\n","Recall: 57.889480676837      Precision: 59.41984561231423      F1-score1: 58.64468091677744       F1-score2: 56.75474326589946\n","THRESHOLD IS =====>  0.33\n","Recall: 57.82562371642831      Precision: 59.53257956962854      F1-score1: 58.66668794631532       F1-score2: 56.75332422233481\n","THRESHOLD IS =====>  0.34\n","Recall: 57.71919544908051      Precision: 59.54370834164582      F1-score1: 58.617257946605605       F1-score2: 56.70407696044387\n","THRESHOLD IS =====>  0.35\n","Recall: 57.61276718173271      Precision: 59.59675273505061      F1-score1: 58.58796866584748       F1-score2: 56.69024128568866\n","THRESHOLD IS =====>  0.36\n","Recall: 57.564874461426186      Precision: 59.65896817718811      F1-score1: 58.593216811795344       F1-score2: 56.700884112423445\n","THRESHOLD IS =====>  0.37\n","Recall: 57.47441043418055      Precision: 59.71712420711774      F1-score1: 58.57430772852622       F1-score2: 56.66127759293187\n","THRESHOLD IS =====>  0.38\n","Recall: 57.426517713874034      Precision: 59.752551111931155      F1-score1: 58.5664482447708       F1-score2: 56.642728666336964\n","THRESHOLD IS =====>  0.39\n","Recall: 57.41055347377186      Precision: 59.84760775740408      F1-score1: 58.603755156280876       F1-score2: 56.637407252969574\n","THRESHOLD IS =====>  0.4\n","Recall: 57.40809743683306      Precision: 59.93807469050188      F1-score1: 58.645812975896284       F1-score2: 56.65186761538096\n","THRESHOLD IS =====>  0.41\n","Recall: 57.381490369996115      Precision: 60.02546981659677      F1-score1: 58.67370916956697       F1-score2: 56.66920021892046\n","THRESHOLD IS =====>  0.42\n","Recall: 57.30965128953635      Precision: 60.08702649616158      F1-score1: 58.66548526707406       F1-score2: 56.661446159442264\n","THRESHOLD IS =====>  0.43\n","Recall: 57.22876580635201      Precision: 60.06869219928196      F1-score1: 58.61434981824474       F1-score2: 56.61720240830196\n","THRESHOLD IS =====>  0.44\n","Recall: 57.17735276643323      Precision: 60.09896838259886      F1-score1: 58.60176858282926       F1-score2: 56.60869465720716\n","THRESHOLD IS =====>  0.45\n","Recall: 57.15606711296366      Precision: 60.20884191877053      F1-score1: 58.64275170311048       F1-score2: 56.62891602800324\n","THRESHOLD IS =====>  0.46\n","Recall: 57.0911458698815      Precision: 60.23379339835036      F1-score1: 58.620380400787575       F1-score2: 56.59767172951757\n","THRESHOLD IS =====>  0.47\n","Recall: 56.93682488222718      Precision: 60.20782780276451      F1-score1: 58.52665861519917       F1-score2: 56.525756628866844\n","THRESHOLD IS =====>  0.48\n","Recall: 56.88893216192066      Precision: 60.29963735033608      F1-score1: 58.54465146027579       F1-score2: 56.51440428034974\n","THRESHOLD IS =====>  0.49\n","Recall: 56.854609045701      Precision: 60.38155097322847      F1-score1: 58.56502760925757       F1-score2: 56.53376408898158\n","THRESHOLD IS =====>  0.5\n","Recall: 56.81203773876188      Precision: 60.45878902417614      F1-score1: 58.57871217408112       F1-score2: 56.5351324524189\n","THRESHOLD IS =====>  0.51\n","Recall: 56.801394912027106      Precision: 60.46421084156932      F1-score1: 58.5755984627354       F1-score2: 56.53406816974543\n","THRESHOLD IS =====>  0.52\n","Recall: 56.6843238179445      Precision: 60.44035484503929      F1-score1: 58.5021138980583       F1-score2: 56.48293192129117\n","THRESHOLD IS =====>  0.53\n","Recall: 56.63563288563288      Precision: 60.46746393200524      F1-score1: 58.48885609082336       F1-score2: 56.462564357820156\n","THRESHOLD IS =====>  0.54\n","Recall: 56.63563288563288      Precision: 60.56162677744709      F1-score1: 58.53287134843691       F1-score2: 56.49473259401139\n","THRESHOLD IS =====>  0.55\n","Recall: 56.539847445019866      Precision: 60.60616404702426      F1-score1: 58.50243172264244       F1-score2: 56.448360277524124\n","THRESHOLD IS =====>  0.56\n","Recall: 56.515901084866606      Precision: 60.67633750608311      F1-score1: 58.522269561810326       F1-score2: 56.43224399704002\n","THRESHOLD IS =====>  0.57\n","Recall: 56.48290832198878      Precision: 60.72379501370686      F1-score1: 58.526627728772084       F1-score2: 56.41386093267995\n","THRESHOLD IS =====>  0.58\n","Recall: 56.47226549525401      Precision: 60.798057084797776      F1-score1: 58.55537779295488       F1-score2: 56.43301802080255\n","THRESHOLD IS =====>  0.59\n","Recall: 56.42969418831487      Precision: 60.91162170436443      F1-score1: 58.585062885016605       F1-score2: 56.45749652229256\n","THRESHOLD IS =====>  0.6\n","Recall: 56.36583722790619      Precision: 61.01319720468656      F1-score1: 58.597516311457674       F1-score2: 56.43940371684343\n","THRESHOLD IS =====>  0.61\n","Recall: 56.36583722790619      Precision: 61.04954730200309      F1-score1: 58.61427546039353       F1-score2: 56.44259656486387\n","THRESHOLD IS =====>  0.62\n","Recall: 56.263666091252304      Precision: 61.113946507260174      F1-score1: 58.58859459962671       F1-score2: 56.38558142164183\n","THRESHOLD IS =====>  0.63\n","Recall: 56.18916630410883      Precision: 61.22247235510532      F1-score1: 58.59793322013657       F1-score2: 56.357301910603695\n","THRESHOLD IS =====>  0.64\n","Recall: 56.114666516965364      Precision: 61.317423755725834      F1-score1: 58.60079264095606       F1-score2: 56.29678983859737\n","THRESHOLD IS =====>  0.65\n","Recall: 56.10029870087342      Precision: 61.421931530627184      F1-score1: 58.640628226083       F1-score2: 56.316352367738446\n","THRESHOLD IS =====>  0.66\n","Recall: 56.08566481411309      Precision: 61.500415921147635      F1-score1: 58.66836774750477       F1-score2: 56.330203693709436\n","THRESHOLD IS =====>  0.67\n","Recall: 55.984557960132676      Precision: 61.57274171227276      F1-score1: 58.64583036121178       F1-score2: 56.26938754093928\n","THRESHOLD IS =====>  0.68\n","Recall: 55.851522625947915      Precision: 61.59032988814951      F1-score1: 58.580712576458374       F1-score2: 56.201577530600524\n","THRESHOLD IS =====>  0.69\n","Recall: 55.77456680186565      Precision: 61.67513070042831      F1-score1: 58.57662932163189       F1-score2: 56.16511548264421\n","THRESHOLD IS =====>  0.7\n","Recall: 55.702727721405886      Precision: 61.73863152415653      F1-score1: 58.565571852613616       F1-score2: 56.109772783623356\n","THRESHOLD IS =====>  0.71\n","Recall: 55.63248506495633      Precision: 61.73923165553925      F1-score1: 58.5269940487953       F1-score2: 56.06005557873374\n","THRESHOLD IS =====>  0.72\n","Recall: 55.55266386444547      Precision: 61.77189449577509      F1-score1: 58.49744229435395       F1-score2: 56.025998533182445\n","THRESHOLD IS =====>  0.73\n","Recall: 55.48375156133777      Precision: 61.88062795739765      F1-score1: 58.507860768773355       F1-score2: 55.990535114098336\n","THRESHOLD IS =====>  0.74\n","Recall: 55.38796612072474      Precision: 61.94478790184515      F1-score1: 58.483171936847235       F1-score2: 55.94051382844486\n","THRESHOLD IS =====>  0.75\n","Recall: 55.334751987050836      Precision: 62.01381618603471      F1-score1: 58.484209766639914       F1-score2: 55.92348530566922\n","THRESHOLD IS =====>  0.76\n","Recall: 55.26843898970335      Precision: 62.153029436073496      F1-score1: 58.50890746753389       F1-score2: 55.89090950202061\n","THRESHOLD IS =====>  0.77\n","Recall: 55.18831370842865      Precision: 62.244477336389096      F1-score1: 58.50440428596815       F1-score2: 55.84405767355959\n","THRESHOLD IS =====>  0.78\n","Recall: 54.996742827202596      Precision: 62.35270649814885      F1-score1: 58.44417308429439       F1-score2: 55.72090496419998\n","THRESHOLD IS =====>  0.79\n","Recall: 54.93288586679391      Precision: 62.469109160952065      F1-score1: 58.45911635365084       F1-score2: 55.695970341564205\n","THRESHOLD IS =====>  0.8\n","Recall: 54.797189825925464      Precision: 62.548948920079475      F1-score1: 58.41703295929539       F1-score2: 55.582092095502055\n","THRESHOLD IS =====>  0.81\n","Recall: 54.68437586253678      Precision: 62.710672127198265      F1-score1: 58.4231451653033       F1-score2: 55.542245997226836\n","THRESHOLD IS =====>  0.82\n","Recall: 54.59710468331157      Precision: 62.738818687502004      F1-score1: 58.38549274911801       F1-score2: 55.46843960637064\n","THRESHOLD IS =====>  0.83\n","Recall: 54.42092789075548      Precision: 62.8809926677947      F1-score1: 58.34588131854327       F1-score2: 55.38152318803659\n","THRESHOLD IS =====>  0.84\n","Recall: 54.30964895045355      Precision: 63.20138180994449      F1-score1: 58.419109032927       F1-score2: 55.34835798775101\n","THRESHOLD IS =====>  0.85\n","Recall: 54.15768458871907      Precision: 63.30383480825959      F1-score1: 58.3746768542189       F1-score2: 55.25687840872353\n","THRESHOLD IS =====>  0.86\n","Recall: 54.0858455082593      Precision: 63.57590251679762      F1-score1: 58.448161773687126       F1-score2: 55.240153966711745\n","THRESHOLD IS =====>  0.87\n","Recall: 53.77241426092001      Precision: 63.68508350491878      F1-score1: 58.31046561701495       F1-score2: 55.00084240556109\n","THRESHOLD IS =====>  0.88\n","Recall: 53.68514308169481      Precision: 63.93140296449501      F1-score1: 58.361967443161234       F1-score2: 54.93059974911154\n","THRESHOLD IS =====>  0.89\n","Recall: 53.36612435031975      Precision: 64.13226962654642      F1-score1: 58.25595669728648       F1-score2: 54.66304376316475\n","THRESHOLD IS =====>  0.9\n","Recall: 53.220051553384884      Precision: 64.44347624026955      F1-score1: 58.296486466071116       F1-score2: 54.58622828405042\n","THRESHOLD IS =====>  0.91\n","Recall: 53.050475847410716      Precision: 64.8509294984216      F1-score1: 58.36016388348783       F1-score2: 54.49983018520022\n","THRESHOLD IS =====>  0.92\n","Recall: 52.8221258130262      Precision: 65.26442873969374      F1-score1: 58.387779693653194       F1-score2: 54.33890768660884\n","THRESHOLD IS =====>  0.93\n","Recall: 52.59889252226417      Precision: 65.81639928698752      F1-score1: 58.46997730453944       F1-score2: 54.19602197858902\n","THRESHOLD IS =====>  0.94\n","Recall: 52.20640027632364      Precision: 66.36265320836337      F1-score1: 58.43945169457076       F1-score2: 53.90402842510122\n","THRESHOLD IS =====>  0.95\n","Recall: 51.717239586013534      Precision: 67.17868912486269      F1-score1: 58.44264640875003       F1-score2: 53.516895602623585\n","THRESHOLD IS =====>  0.96\n","Recall: 51.028078544840994      Precision: 68.48353986731756      F1-score1: 58.48106649056486       F1-score2: 52.961586536778114\n","THRESHOLD IS =====>  0.97\n","Recall: 50.04521349588399      Precision: 69.39090208172706      F1-score1: 58.15129690977634       F1-score2: 52.04480837383135\n","THRESHOLD IS =====>  0.98\n","Recall: 48.36291590841399      Precision: 71.97588884348181      F1-score1: 57.852724509727615       F1-score2: 50.54737532227953\n","THRESHOLD IS =====>  0.99\n","Recall: 42.09018587131614      Precision: 77.40225314777999      F1-score1: 54.52855843587028       F1-score2: 44.272542059898385\n","THRESHOLD IS =====>  0.999\n","Recall: 2.781298097390051      Precision: 73.65269461077844      F1-score1: 5.360183136598495       F1-score2: 3.1165237487076567\n","AUPR: 0.449\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["from matplotlib import pyplot as plt\n","\n","# Testing\n","def final_model_testing(filename):\n","    print('Extracting features based on GRU model...... ')\n","    dataframe2 = pd.read_csv(filename, header=None)\n","    dataset2 = dataframe2.values\n","    overlap = 50\n","    X_test = dataset2[:,0]\n","    Y_test = dataset2[:,1:len(dataset2[0])]\n","    c_p = []\n","    for tag, row in enumerate(X_test):\n","        pos = math.ceil(len(row) / overlap)\n","        if(pos < math.ceil(segmentSize/ overlap)):\n","            pos = math.ceil(segmentSize/ overlap)\n","        segment = [ ]\n","        for itr in range(pos - math.ceil(segmentSize/overlap) + 1):\n","            init = itr * overlap\n","            segment.append(row[init : init + segmentSize])\n","        seg_nGram = nGram(segment, chunkSize, dict_Prop)\n","        test_seg = sequence.pad_sequences(seg_nGram, maxlen=max_seq_len)\n","        preds = model.predict(test_seg)\n","        c_p.append(cls_predict(preds))\n","    c_p = np.array(c_p)\n","    return c_p, Y_test\n","\n","def test_fun(file):\n","    X_test_new, Y_test_new = final_model_testing(file)\n","    print(X_test_new.shape, Y_test_new.shape)\n","    Y_test_new = np.array(Y_test_new).astype(None)\n","\n","    fmax, tmax = 0.0, 0.0\n","    precisions, recalls = [], []\n","    for t in range(1, 101, 1):\n","        test_preds = model1.predict(X_test_new)\n","\n","        threshold = t / 100.0\n","        if threshold == 1.0:\n","          threshold = 0.999\n","        print(\"THRESHOLD IS =====> \", threshold)\n","        test_preds[test_preds>=threshold] = int(1)\n","        test_preds[test_preds<threshold] = int(0)\n","\n","        rec = recall(Y_test_new, test_preds)\n","        pre = precision(Y_test_new, test_preds)\n","        if math.isnan(pre):\n","          pre = 0.0\n","        recalls.append(rec)\n","        precisions.append(pre)\n","\n","        f1 = f_score(Y_test_new, test_preds)*100\n","        f = 2 * pre * rec / (pre + rec)\n","        if math.isnan(f):\n","          f = 0.0\n","        print('Recall: {0}'.format(rec*100), '     Precision: {0}'.format(pre*100),\n","              '     F1-score1: {0}'.format(f*100), '      F1-score2: {0}'.format(f1))\n","\n","        if fmax < f:\n","            fmax = f\n","            tmax = threshold\n","    \n","    precisions = np.array(precisions)\n","    recalls = np.array(recalls)\n","    sorted_index = np.argsort(recalls)\n","    recalls = recalls[sorted_index]\n","    precisions = precisions[sorted_index]\n","    aupr = np.trapz(precisions, recalls)\n","    print(f'AUPR: {aupr:0.3f}')\n","\n","    plt.figure()\n","    plt.plot(recalls, precisions, color='darkorange', lw=2, label=f'AUPR curve (area = {aupr:0.2f})')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Area Under the Precision-Recall curve')\n","    plt.legend(loc=\"upper right\")\n","    plt.savefig(f'aupr.pdf')\n","\n","    return tmax\n","\n","th_set = test_fun(\"/content/gdrive/MyDrive/B_tech_minor_project/dataset/MF/testData1.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPTI3zRR4aql","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649149851123,"user_tz":-330,"elapsed":271461,"user":{"displayName":"Ashutosh Raman","userId":"11279823942514050971"}},"outputId":"deb784c0-21cd-4abf-ca66-b83fb059a67d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best Threshold:  0.03\n","Extracting features based on GRU model...... \n","(3132, 135) (3132, 135)\n","   Recall: 62.710145147884624     Precision: 56.70700523551994     F1-score: 59.55768527056565     F1-score: 56.70895373219081\n","Extracting features based on GRU model...... \n","(255, 135) (255, 135)\n","   Recall: 42.15686274509804     Precision: 37.10754604872252     F1-score: 39.47137812261979     F1-score: 37.45191409897292\n","Extracting features based on GRU model...... \n","(1268, 135) (1268, 135)\n","   Recall: 58.869235391317396     Precision: 53.609494835487595     F1-score: 56.1163868816121     F1-score: 53.644628234741134\n","Extracting features based on GRU model...... \n","(1160, 135) (1160, 135)\n","   Recall: 70.13297071702243     Precision: 64.56730856477306     F1-score: 67.2351562297343     F1-score: 64.43865290670564\n","Extracting features based on GRU model...... \n","(449, 135) (449, 135)\n","   Recall: 66.05286880899352     Precision: 56.27839369418523     F1-score: 60.775132691307114     F1-score: 56.32957465602046\n","/n\n","code Completion date is : 2022-04-05 09:10:50.182861\n"]}],"source":["def test_fun(file):\n","    X_test_new, Y_test_new = final_model_testing(file)\n","    print(X_test_new.shape, Y_test_new.shape)\n","    test_preds = model1.predict(X_test_new)\n","    Y_test_new = np.array(Y_test_new).astype(None)\n","    test_preds[test_preds>=th_set] = int(1)\n","    test_preds[test_preds<th_set] = int(0)\n","    rec = recall(Y_test_new, test_preds)*100\n","    pre = precision(Y_test_new, test_preds)*100\n","    f = 2 * pre * rec / (pre + rec)\n","    f1 = f_score(Y_test_new, test_preds)*100\n","    print('   Recall: {0}'.format(rec),  '    Precision: {0}'.format(pre),  '    F1-score: {0}'.format(f), '    F1-score: {0}'.format(f1))\n","\n","def test_fun_specific(file):\n","    X_test_new, Y_test_new = final_model(file)\n","    print(X_test_new.shape, Y_test_new.shape)\n","    test_preds = model1.predict(X_test_new)\n","    Y_test_new = np.array(Y_test_new).astype(None)\n","    test_preds[test_preds>=th_set] = int(1)\n","    test_preds[test_preds<th_set] = int(0)\n","    rec = recall(Y_test_new, test_preds)*100\n","    pre = precision(Y_test_new, test_preds)*100\n","    f = 2 * pre * rec / (pre + rec)\n","    f1 = f_score(Y_test_new, test_preds)*100\n","    print('   Recall: {0}'.format(rec),  '    Precision: {0}'.format(pre),  '    F1-score: {0}'.format(f), '    F1-score: {0}'.format(f1))\n","\n","print(\"Best Threshold: \", th_set)\n","test_fun('/content/gdrive/MyDrive/B_tech_minor_project/dataset/MF/testData1.csv')\n","test_fun_specific(\"testData200.csv\")\n","test_fun_specific(\"testData500.csv\")\n","test_fun_specific(\"testData1000.csv\")\n","test_fun_specific(\"testData16000.csv\")\n","\n","print('/n')\n","print(\"code Completion date is :\", datetime.datetime.now())"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Gated_Dilated_CNN_32_300_mf_4_4M.ipynb","provenance":[{"file_id":"1uJFoByu21wT3eU7Dc1bz2Wpuz-9SkW-j","timestamp":1649146960438}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}